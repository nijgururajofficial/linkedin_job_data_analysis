{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68478ae7-1b21-425c-b681-8959c00d95e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44f7d2e-d998-4302-984b-9153e1d15957",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://www.linkedin.com/jobs/search?keywords=Database%20Administrator&location=United%20States\"\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a6677a-68d9-49d3-a2bd-7f804ca82492",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_postings = []\n",
    "unique_jobs = set() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c23915-a04c-4c13-9b39-e733f9125c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs_per_page = 25\n",
    "max_pages = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef135e2-9e8e-4c63-8bd6-5337db15ead9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(base_url, headers=headers)\n",
    "print(response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d99f18a2-aa25-47e2-8992-bc04d996ed5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for page in range(0, max_pages * jobs_per_page, jobs_per_page):\n",
    "    url = f\"{base_url}&start={page}\"\n",
    "    \n",
    "    response = requests.get(url, headers=headers)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    \n",
    "    job_cards = soup.find_all('div', class_='base-search-card__info')  # Job card containing all info\n",
    "    \n",
    "    for card in job_cards:\n",
    "        job_title = card.find('h3', class_='base-search-card__title').get_text(strip=True)\n",
    "        company = card.find('h4', class_='base-search-card__subtitle').get_text(strip=True)\n",
    "        location = card.find('span', class_='job-search-card__location').get_text(strip=True)\n",
    "        \n",
    "        job_data = (job_title, company, location)\n",
    "        \n",
    "        # Check if the job is already added\n",
    "        if job_data not in unique_jobs:\n",
    "            unique_jobs.add(job_data)\n",
    "            job_postings.append({\n",
    "                \"Job Title\": job_title,\n",
    "                \"Company\": company,\n",
    "                \"Location\": location\n",
    "            })\n",
    "    \n",
    "    time.sleep(2)  # Sleep to avoid getting blocked by LinkedIn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17193bd-7e9f-4029-a1d5-bb0cf941cba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Total unique job postings scraped: {len(job_postings)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471678ae-7a21-497b-aac8-6cb000979fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "df = pd.DataFrame(job_postings)\n",
    "csv_file_path = '../data/raw/linkedin_job_postings.csv'\n",
    "\n",
    "if os.path.exists(csv_file_path):\n",
    "    existing_jobs_df = pd.read_csv(csv_file_path)\n",
    "    updated_jobs_df = pd.concat([existing_jobs_df, df], ignore_index=True)\n",
    "    updated_jobs_df.drop_duplicates(subset=['Job Title', 'Company', 'Location'], keep='last', inplace=True)\n",
    "else:\n",
    "    updated_jobs_df = df\n",
    "\n",
    "updated_jobs_df.to_csv(csv_file_path, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
